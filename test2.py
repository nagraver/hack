import os
import requests
import gradio as gr
import logging
from typing import Optional, List
from uuid import uuid4
import subprocess
import tempfile

from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import SentenceTransformersTokenTextSplitter
from langchain_core.language_models.llms import LLM
from langchain_core.documents import Document
from langchain_qdrant import QdrantVectorStore
from qdrant_client import QdrantClient
from qdrant_client.http.models import Distance, VectorParams

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
COLLECTION_NAME = os.getenv("COLLECTION_NAME", "code-assistant-store")

class LMStudioLLM(LLM):
    model: str = "local-model"
    base_url: str = "http://127.0.0.1:1234/v1"

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
        }
        response = requests.post(f"{self.base_url}/chat/completions", json=payload)
        return response.json()["choices"][0]["message"]["content"]

    @property
    def _llm_type(self) -> str:
        return "lmstudio-llm"

def configure_qdrant() -> QdrantVectorStore:
    """Configure and return a Qdrant vector store."""
    logger.info("Configuring Qdrant client and vector store...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-m3",
        encode_kwargs={'truncation': True, 'max_length': 512}
    )
    embeddings.embed_query("test")  # –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏

    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ Qdrant
    client = QdrantClient(path='/tmp/langchain_qdrant')

    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    try:
        client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=1024, distance=Distance.COSINE),
        )
    except ValueError:
        logger.info("Collection already exists. Skipping creation.")

    # –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    vector_store = QdrantVectorStore(
        client=client,
        collection_name=COLLECTION_NAME,
        embedding=embeddings,
    )
    
    logger.info("Qdrant configuration completed.")
    return vector_store

def clone_github_repo(repo_url: str, temp_dir: str) -> str:
    """Clone GitHub repository to temporary directory."""
    try:
        repo_name = repo_url.split("/")[-1]
        if repo_name.endswith(".git"):
            repo_name = repo_name[:-4]
        repo_path = os.path.join(temp_dir, repo_name)
        
        subprocess.run(["git", "clone", repo_url, repo_path], check=True)
        logger.info(f"Repository cloned successfully to {repo_path}")
        return repo_path
    except subprocess.CalledProcessError as e:
        logger.error(f"Failed to clone repository: {e}")
        raise

def load_documents_from_repo(repo_path: str) -> List[Document]:
    """Load documents from repository."""
    documents = []
    
    for root, _, files in os.walk(repo_path):
        for file in files:
            if file.endswith(('.txt', '.md', '.py', '.js', '.java', '.cpp', '.h', '.html', '.css')):
                file_path = os.path.join(root, file)
                try:
                    loader = TextLoader(file_path, encoding='utf-8')
                    loaded_docs = loader.load()
                    for doc in loaded_docs:
                        doc.metadata["source_file"] = file_path  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    documents.extend(loaded_docs)
                    logger.info(f"Loaded {file_path}")
                except Exception as e:
                    logger.warning(f"Could not load {file_path}: {e}")
    
    return documents

def add_repository_to_store(vector_store: QdrantVectorStore, repo_url: str) -> None:
    """Add repository documents to vector store."""
    with tempfile.TemporaryDirectory() as temp_dir:
        try:
            # –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
            repo_path = clone_github_repo(repo_url, temp_dir)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
            documents = load_documents_from_repo(repo_path)
            
            if not documents:
                raise ValueError("No documents found in repository")
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ —á–∞–Ω–∫–∏
            splitter = SentenceTransformersTokenTextSplitter(
                tokens_per_chunk=512,
                chunk_overlap=50,
                model_name="BAAI/bge-m3"
            )
            texts = splitter.split_documents(documents)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            ids = [str(uuid4()) for _ in texts]
            vector_store.add_documents(documents=texts, ids=ids)
            logger.info(f"Added {len(texts)} documents from repository to vector store")
            
        except Exception as e:
            logger.error(f"Error processing repository: {e}")
            raise

def load_or_create_vector_store(vector_store: QdrantVectorStore, file_path: str = None) -> QdrantVectorStore:
    """Load or create vector store with documents."""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    client = vector_store.client
    collection_info = client.get_collection(COLLECTION_NAME)
    
    if collection_info.vectors_count == 0 and file_path:
        logger.info("No documents in vector store. Creating new index...")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        loader = TextLoader(file_path)
        documents = loader.load()
        for doc in documents:
            doc.metadata["source_file"] = file_path  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —á–∞–Ω–∫–∏
        splitter = SentenceTransformersTokenTextSplitter(
            tokens_per_chunk=512,
            chunk_overlap=50,
            model_name="BAAI/bge-m3"
        )
        texts = splitter.split_documents(documents)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        ids = [str(uuid4()) for _ in texts]
        vector_store.add_documents(documents=texts, ids=ids)
        logger.info(f"Added {len(texts)} documents to vector store.")
    else:
        logger.info(f"Vector store already contains {collection_info.vectors_count} vectors. Using existing index.")
    
    return vector_store

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ ===
llm = LMStudioLLM()
vector_store = configure_qdrant()

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
FILE_PATH = r"./my_notes.txt"
if os.path.exists(FILE_PATH):
    vector_store = load_or_create_vector_store(vector_store, FILE_PATH)
else:
    vector_store = load_or_create_vector_store(vector_store)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞
retriever = vector_store.as_retriever(
    search_type="mmr",
    search_kwargs={"k": 5}
)

# === –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç ===
prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template=(
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç –∏ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∫–∞—Å–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–µ–∫—Ç–∞\n\n"
        "–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–í–æ–ø—Ä–æ—Å: {question}\n–û—Ç–≤–µ—Ç:"
    ),
)

# === –°–±–æ—Ä–∫–∞ —Ü–µ–ø–æ—á–∫–∏ ===
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt_template},
    return_source_documents=True,  # –í–∫–ª—é—á–∞–µ–º –≤–æ–∑–≤—Ä–∞—Ç –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
)

# === –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è Gradio ===
with gr.Blocks(css="style.css", theme=gr.themes.Default()) as demo:  # –î–æ–±–∞–≤–ª—è–µ–º CSS
    gr.Markdown("## üß† –õ–æ–∫–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∫–æ–¥—É")
    gr.Markdown("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç LLaMA 3.1 —á–µ—Ä–µ–∑ LM Studio + LangChain + Qdrant + bge-m3")
    
    with gr.Tab("üí¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", id="qa_tab"):
        with gr.Row(variant="panel"):
            with gr.Column(scale=7):
                question_input = gr.Textbox(
                    lines=2,
                    placeholder="–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –æ –ø—Ä–æ–µ–∫—Ç–µ...",
                    label=" ",
                    elem_classes=["prompt-box"]
                )
                
                with gr.Accordion("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏", open=False):
                    with gr.Group():
                        temperature = gr.Slider(0.1, 2.0, value=0.7, step=0.1, label="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞")
                        max_tokens = gr.Slider(128, 4096, value=1024, step=128, label="–ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤")
                        top_p = gr.Slider(0.1, 1.0, value=0.9, step=0.1, label="Top-p –≤—ã–±–æ—Ä–∫–∞")
                
                with gr.Accordion("üîç –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞", open=False):
                    with gr.Row():
                        k_results = gr.Slider(1, 10, value=5, step=1, label="–†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                        fetch_k = gr.Slider(5, 50, value=20, step=5, label="–ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
                    mmr_lambda = gr.Slider(0.0, 1.0, value=0.5, step=0.1, label="–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ (MMR)")
                
                gr.Examples(
                    examples=[
                        "–ü–æ–∫–∞–∂–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞",
                        "–ö–∞–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è?",
                        "–û–±—ä—è—Å–Ω–∏ –º–µ—Ö–∞–Ω–∏–∑–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"
                    ],
                    inputs=question_input,
                    label="–ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤"
                )

            with gr.Column(scale=3):
                answer_output = gr.Textbox(
                    label="üìù –û—Ç–≤–µ—Ç",
                    elem_classes=["response-box"],
                    interactive=False
                )
                ask_button = gr.Button("üöÄ –û—Ç–ø—Ä–∞–≤–∏—Ç—å", variant="primary")

        ask_button.click(
            answer_question,
            inputs=[question_input, temperature, max_tokens, top_p, k_results, fetch_k, mmr_lambda],
            outputs=answer_output
        )
    
    with gr.Tab("‚ûï –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", id="repo_tab"):
        with gr.Row():
            with gr.Column():
                gr.Markdown("### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è")
                with gr.Group():
                    repo_url_input = gr.Textbox(
                        placeholder="https://github.com/username/repository.git",
                        label="GitHub URL",
                        elem_classes=["repo-input"]
                    )
                    with gr.Accordion("üîß –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏", open=False):
                        chunk_size = gr.Slider(128, 1024, value=512, step=64, label="–†–∞–∑–º–µ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞")
                        chunk_overlap = gr.Slider(0, 256, value=50, step=16, label="–ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
                add_repo_button = gr.Button("üì• –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", variant="primary")
                
            with gr.Column():
                repo_status_output = gr.Textbox(
                    label="–°—Ç–∞—Ç—É—Å –æ–ø–µ—Ä–∞—Ü–∏–∏",
                    elem_classes=["status-box"],
                    interactive=False
                )
                gr.Markdown("### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
                gr.Markdown("- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ HTTPS URL —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è\n- –ë–æ–ª—å—à–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –¥–æ–ª—å—à–µ\n- –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ 512-768 —Ç–æ–∫–µ–Ω–æ–≤")

        add_repo_button.click(
            add_repository,
            inputs=[repo_url_input, chunk_size, chunk_overlap],
            outputs=repo_status_output
        )
# === –ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ ===
if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)